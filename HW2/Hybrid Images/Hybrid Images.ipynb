{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51610d6b",
   "metadata": {},
   "source": [
    "# 3-Template Matching\n",
    "in this section we have two main goals :\n",
    "1) aligning two images :\n",
    "* mark eyes of each image \n",
    "\n",
    "* shift second image based on differences between eyes location\n",
    "\n",
    "* remove portions of images that are not aligned \n",
    "\n",
    "2) use to aligned image two make hybrid image :\n",
    "\n",
    "* make a Gaussian highpass filter with specific sigma to implement it on near image \n",
    "\n",
    "* make a Gaussian lowpass filter with specific sigma to implement it on far image \n",
    "\n",
    "* take inverse Fourier transform from both high_frequncy and low_frequency image and add them together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d578a4a2",
   "metadata": {},
   "source": [
    "## aligning images \n",
    "to do so , we use `plt.ginput(2)` to get coordinates of eyes in each image by clicking on them . function , then we pass two images and their eye's coordinates to `align(image1, image2, points1, points2)`. this function align images using `np.roll(image, -delta, axis=) `function .\n",
    "\n",
    "note that because `np.roll` shift start of image to the end of that and vice versa ,after shifting we have to remove unaligned portions of two images \n",
    "\n",
    "* original images :\n",
    "<table><tr>\n",
    "<td> <img src=\"res19-near.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"res20-far.jpeg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "\n",
    "* aligned images( size of the right image changes and shifted a little too ) :\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"res21-near.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"res22-far.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    " $\\color{red}{\\text{* note that plt.ginput() doesn't work in jupyter so to examine the Validity of question4's code , run q4.py in any IDE(vscode,pycharm,...)}}$\n",
    " \n",
    " $\\color{red}{\\text{* when you run the code of q4.py , first image appears! mark her eyes from left to right and after marking first image's eyes , second image }}$\n",
    " $\\color{red}{\\text{appears. do the same thing for second image. after a few seconds , all of the result will be save }}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83104f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(im1, im2, p1, p3):\n",
    "    im1 = np.array(im1)\n",
    "    [c1, c2, c3] = im1.shape\n",
    "\n",
    "    # difference in x position for left eyes of two images\n",
    "    delta_x = p3[0]-p1[0]\n",
    "    \n",
    "    # difference in y position for left eyes of two images\n",
    "    delta_y = p3[1]-p1[1]\n",
    "\n",
    "    im2 = np.roll(im2, int(-delta_y), axis=0)  # shift image up/down\n",
    "\n",
    "    im2 = np.roll(im2, int(-delta_x), axis=1)  # shift image right/left\n",
    "\n",
    "    if(delta_x > 0):\n",
    "\n",
    "        im1 = im1[:, :int(c2-delta_x), :]\n",
    "                                          # crop image after shifting image\n",
    "        im2 = im2[:, :int(c2-delta_x), :]\n",
    "\n",
    "    else:\n",
    "\n",
    "        im1 = im1[:, int(-delta_x):, :]\n",
    "                                         # crop image after shifting image\n",
    "        im2 = im2[:, int(-delta_x):, :]\n",
    "\n",
    "    if(delta_y > 0):\n",
    "\n",
    "        im1 = im1[:int(c1-delta_y), :, :]\n",
    "                                         # crop image after shifting image\n",
    "        im2 = im2[:int(c1-delta_y), :, :]\n",
    "\n",
    "    else:\n",
    "\n",
    "        im1 = im1[int(-delta_y):, :, :]\n",
    "                                        # crop image after shifting image\n",
    "        im2 = im2[int(-delta_y):, :, :]\n",
    "\n",
    "    return im1, im2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b74251",
   "metadata": {},
   "source": [
    "## make hybrid images\n",
    "first of all we get Fourier transform of aligned image .(left side is fft of near image and right side is  fft of far image):\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"res23-dft-near.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "<td> <img src=\"res24-dft-far.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c581b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_cal(image):\n",
    "\n",
    "    dft = np.fft.fft2(image)\n",
    "\n",
    "# # apply shift of origin to center of image\n",
    "    dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "    return dft_shift\n",
    "\n",
    "# ---------------------------------\n",
    "\n",
    "def fft_inverse_cal(dft):\n",
    "\n",
    "    ishift = np.fft.ifftshift(dft)\n",
    "\n",
    "    ifft = np.fft.ifft2(ishift)\n",
    "\n",
    "    return np.real(ifft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9112d12",
   "metadata": {},
   "source": [
    "to make hybrid images first we have to make highpass Gaussian and low pass Gaussian filter .\n",
    "\n",
    "below are the picture of these filters (left side is high pass and right side is low pass ) \n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"res25-highpass-65.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "<td> <img src=\"res26-lowpass-20.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d339ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_guassian(n1: int, n2: int, sigma):\n",
    "\n",
    "    c1 = (n1-1)//2\n",
    "\n",
    "    c2 = (n2-1)//2\n",
    "\n",
    "    matrix = np.zeros([n1, n2])\n",
    "\n",
    "    for x in range(0, n1):\n",
    "        for y in range(0, n2):\n",
    "\n",
    "            matrix[x, y] = np.exp(-((x-c1)**2+(y-c2)**2)/2/(sigma**2))\n",
    "\n",
    "    plt.imsave(f'res26-lowpass-{sigma}.jpg', matrix)\n",
    "\n",
    "    return matrix\n",
    "# ------------------------------\n",
    "def high_guassian(n1: int, n2: int, sigma):\n",
    "\n",
    "    c1 = (n1-1)//2\n",
    "\n",
    "    c2 = (n2-1)//2\n",
    "\n",
    "    matrix = np.zeros([n1, n2], dtype='float32')\n",
    "\n",
    "    for x in range(0, n1):\n",
    "        for y in range(0, n2):\n",
    "\n",
    "            matrix[x, y] = np.exp(-((x-c1)**2+(y-c2)**2)/2/(sigma**2))\n",
    "\n",
    "    matrix = 1-matrix\n",
    "\n",
    "    plt.imsave(f'res25-highpass-{sigma}.jpg', matrix)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bbd276",
   "metadata": {},
   "source": [
    "after that we apply filters to fft of images (lowpass filter for far image and highpass filter for near image) .\n",
    "\n",
    "below are the fft of filtered images (left side is fft of highpassed image and right side is fft of lowpassed image):\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"res27-highpassed.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "<td> <img src=\"res28-lowpassed.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "</tr></table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f733b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(r, g, b, mask2):\n",
    "\n",
    "    eq1_r = mask2*r\n",
    "    eq1_g = mask2*g\n",
    "    eq1_b = mask2*b\n",
    "\n",
    "    return eq1_r, eq1_g, eq1_b\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "def mergging(r, g, b, image1):\n",
    "\n",
    "    merged_image = np.zeros_like(image1)\n",
    "\n",
    "    r_abs = np.abs(r)\n",
    "    g_abs = np.abs(g)\n",
    "    b_abs = np.abs(b)\n",
    "\n",
    "    merged_image = cv2.merge((r_abs, g_abs, b_abs))\n",
    "\n",
    "    return merged_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f6ba9",
   "metadata": {},
   "source": [
    "in the next step we sum highpassed and lowpassed image and plot its dft : \n",
    "<table><tr>\n",
    "<td> <img src=\"res29-hybrid.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/> </td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f289f6",
   "metadata": {},
   "source": [
    "in the last step we get inverse Fourier transform and plot images with different resolutions : \n",
    "<table><tr>\n",
    "<td> <img src=\"res30-hybrid-near.jpg\" alt=\"Drawing\" style=\"width: 1300px;\"/> </td>\n",
    "<td> <img src=\"res31-hybrid-far.jpg\" alt=\"Drawing\" style=\"width: 150px;\"/> </td>\n",
    "</tr></table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2cb905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_to_time_domain(r, g, b, image):\n",
    "\n",
    "    image1 = np.array(image)\n",
    "\n",
    "    [c1, c2, c3] = image1.shape\n",
    "\n",
    "    time_domain_image = np.zeros([c1, c2, c3])\n",
    "\n",
    "    # print(b[350, 350], 'freq to time')\n",
    "\n",
    "    r_ifft = (fft_inverse_cal(r)).astype('uint8')\n",
    "    g_ifft = (fft_inverse_cal(g)).astype('uint8')\n",
    "    b_ifft = (fft_inverse_cal(b)).astype('uint8')\n",
    "\n",
    "    # print(b_ifft[350, 350], 'freq to time1')\n",
    "\n",
    "    time_domain_image = mergging(\n",
    "        r_ifft, g_ifft, b_ifft, image).clip(0, 255)\n",
    "\n",
    "    return time_domain_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2c1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as im\n",
    "\n",
    "# --------------------------------\n",
    "# Read first not_aligned image\n",
    "\n",
    "image1 = cv2.imread(\"res19-near.jpg\")              \n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "image1 = np.array(image1[:, :, :])\n",
    "[c1, c2, c3] = image1.shape\n",
    "plt.imshow(image1)\n",
    "(p1, p2) = plt.ginput(2)                  #marking eyes of the first image\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# read second not aligned image\n",
    "image2 = cv2.imread(\"res20-far.jpeg\")\n",
    "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
    "image2 = np.array(image2)\n",
    "image2 = cv2.resize(image2, dsize=(c2, c1), interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(image2)\n",
    "(p3, p4) = plt.ginput(2)                 #marking eyes of the first image\n",
    "plt.close()\n",
    "\n",
    "#----------------------------------------- aligning\n",
    "im1, im2 = align(image1, image2, p1, p3)\n",
    "im1 = np.array(im1)\n",
    "im2 = np.array(im2)\n",
    "\n",
    "# ---------------------------------------- store aligned images\n",
    "data = im.fromarray(np.uint8(im2))\n",
    "data.save('res22-far.jpg')  # save the result\n",
    "\n",
    "data = im.fromarray(np.uint8(im1))\n",
    "data.save('res21-near.jpg')  # save the result\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "image1 = cv2.imread(\"res21-near.jpg\")\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "image1_grayscale = cv2.cvtColor(image1, cv2.COLOR_RGB2GRAY)\n",
    "image1 = np.array(image1[:, :, :])\n",
    "[c1, c2, c3] = image1.shape\n",
    "\n",
    "# ------------------------------------\n",
    "\n",
    "image2 = cv2.imread(\"res22-far.jpg\")\n",
    "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
    "image2_grayscale = cv2.cvtColor(image2, cv2.COLOR_RGB2GRAY)\n",
    "image2 = np.array(image2[:, :, :])\n",
    "[c1, c2, c3] = image2.shape\n",
    "\n",
    "# ------------------------------------dft of first aligned image \n",
    "\n",
    "r1, g1, b1 = cv2.split(image1)\n",
    "\n",
    "r1_dft = fft_cal(r1)\n",
    "g1_dft = fft_cal(g1)\n",
    "b1_dft = fft_cal(b1)\n",
    "\n",
    "# print(b1_dft[350, 350], 'sa')\n",
    "\n",
    "# ----------------------------------- dft of second aligned image \n",
    "r2, g2, b2 = cv2.split(image2)\n",
    "\n",
    "r2_dft = fft_cal(r2)\n",
    "g2_dft = fft_cal(g2)\n",
    "b2_dft = fft_cal(b2)\n",
    "\n",
    "# -----------------------------------\n",
    "low = low_guassian(image1.shape[0], image1.shape[1], 20)\n",
    "plt.imsave('lowpassfilter.jpg', low)\n",
    "\n",
    "high = high_guassian(image1.shape[0], image1.shape[1], 65)\n",
    "plt.imsave('highpassfilter.jpg', high)\n",
    "# ------------------------------------\n",
    "\n",
    "r_filtered, g_filtered, b_filtered = filtering(r1_dft, g1_dft, b1_dft, high)\n",
    "image_high = freq_to_time_domain(r_filtered, g_filtered, b_filtered, image1)\n",
    "\n",
    "r_filtered2, g_filtered2, b_filtered2 = filtering(r2_dft, g2_dft, b2_dft, low)\n",
    "image_low = freq_to_time_domain(r_filtered2, g_filtered2, b_filtered2, image2)\n",
    "\n",
    "# -------------------------------------add highpassed and lowpassed image \n",
    "final_image = (1*image_high+1*image_low)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
